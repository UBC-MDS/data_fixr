[
  {
    "objectID": "DEVELOPMENT.html",
    "href": "DEVELOPMENT.html",
    "title": "Development Guide",
    "section": "",
    "text": "Welcome to your shiny new package. This page will help you get started with using Hatch to manage your package.\nIf you look at your project, you will see that a pyproject.toml file. This file stores both your package configuration and settings for development tools like Hatch that you will use to work on your package.\nThis file is written using a .toml format. You can learn more about toml here. Here’s the TL&DR:\n\nEach [] section in the toml file is called a table.\nYou can nest tables with double brackets like this[[]]\nTables contain information about a element that you want to configure.\n\nWe are using Hatch as the default packaging tool. Hatch allows you to configure and run environments and scripts similar to workflow tools like tox or nox.\nHach, by default, uses virtual environments (venv) to manage environments. But you can configure it to use other environment tools.Read the hatch documentation to learn more about environments.\nFor this template, we have set up Hatch environments for you to use. At the bottom of your pyproject.toml file, notice a hatch environment section that looks like this:\n########################################\n# Hatch Environments\n########################################\nBelow is the Hatch environment to install your package. Notice that it defines pip and twine as two packages that the environment needs.\n[tool.hatch.envs.build]\ndescription = \"\"\"Test the installation the package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\nThe table below defines the scripts that you will run build and check your package.\n[tool.hatch.envs.build.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\ndetached = true\nYou can enter that environment to check it out:\n$ hatch shell build\nIf you run pip list, in the environment, twine will be there:\n$ pip list\nHatch by default, installs your package in editable mode (-e) into its virtual environments. But if detached=True is set, then it will skip installing your package into the virtual enviornment.\n\n\nBelow you see the Hatch environment test table.\ntool.hatch.envs says, “Hey, Hatch, this is the definition for an environment.” test is the name of the environment.\nThe environment below defines the dependencies that Hatch needs to install into the environment named test.\n[tool.hatch.envs.test]\ndescription = \"\"\"Run the test suite.\"\"\"\ndependencies = [\n    \"pytest\",\n    \"pytest-cov\",\n    \"pytest-raises\",\n    \"pytest-randomly\",\n    \"pytest-xdist\",\n]\nTo enter a Hatch environment use:\nhatch shell environmentname\nSo you can enter the test environment above with:\nhatch shell test\n\n\n\nIf the environment has a matrix associated with it, that tells Hatch to run the test scripts across different Python versions.\n[[tool.hatch.envs.test.matrix]]\npython = [\"3.10\", \"3.11\", \"3.12\", \"3.13\"]\nIf you run hatch shell test, you will see the output below. To enter an environment with a matrix attached to it, you need to pick the Python environment version that you want to open.\n$ hatch shell test                           \nEnvironment `test` defines a matrix, choose one of the following instead:\n\ntest.py3.10\ntest.py3.11\ntest.py3.12\ntest.py3.13\nOpen the Python 3.13 environment like this:\n$ hatch shell test.py3.13\nTo leave an environment use:\n$ deactivate\n\n\n\nIn the tests section of your pyproject.toml, you will see a tool.hatch.envs.test.scripts table.\nThis table defines the commands that you want Hatch to run in the test environment. Notice that the script has one command called run.\n[tool.hatch.envs.test.scripts]\nrun = \"pytest {args:--cov=greatproject --cov-report=term-missing}\"\nTo run this script , use:\nhatch run test:run\n\nhatch run: calls Hatch and tells it that it will be running a command\ntest:run: defines the environment you want it to run (test) and defines the name of the “script” to berun.\n\nIf you have a Hatch matrix setup for tests, it will both install the necessary Python version using UV and run your tests on each version of the Python versions that you declare in the matrix table. In this case, there are 4 Python versions in the environment, so your tests will run 4 times, once in each Python version listed in the matrix table.\n@lwasser ➜ /workspaces/pyopensci-scipy25-create-python-package (main) $ hatch run test:run\n──────────────────────────────────────────────────────────────────────── test.py3.10 ────────────────────────────────────────────────────────────────────────\n==================================================================== test session starts ====================================================================\nplatform linux -- Python 3.10.16, pytest-8.4.1, pluggy-1.6.0\nUsing --randomly-seed=1490740387\nrootdir: /workspaces/pyopensci-scipy25-create-python-package\nconfigfile: pyproject.toml\ntestpaths: tests\nplugins: xdist-3.8.0, randomly-3.16.0, raises-0.11, cov-6.2.1\ncollected 2 items                                                                                                                                           \n\ntests/system/test_import.py .                                                                                                                         [ 50%]\ntests/unit/test_example.py .                                                                                                                          [100%]\n\n====================================================================== tests coverage =======================================================================\n_____________________________________________________ coverage: platform linux, python 3.10.16-final-0 ______________________________________________________\n\nName                           Stmts   Miss Branch BrPart    Cover   Missing\n----------------------------------------------------------------------------\nsrc/greatproject/__init__.py       0      0      0      0  100.00%\nsrc/greatproject/example.py        2      0      0      0  100.00%\n----------------------------------------------------------------------------\nTOTAL                              2      0      0      0  100.00%\n===================================================================== 2 passed in 0.05s =====================================================================\n──────────────────────────────────────────────────────────────────────── test.py3.11 ────────────────────────────────────────────────────────────────────────\n==================================================================== test session starts ====================================================================\nplatform linux -- Python 3.11.12, pytest-8.4.1, pluggy-1.6.0\nUsing --randomly-seed=1596865075\nrootdir: /workspaces/pyopensci-scipy25-create-python-package\nconfigfile: pyproject.toml\ntestpaths: tests\nplugins: xdist-3.8.0, randomly-3.16.0, raises-0.11, cov-6.2.1\ncollected 2 items                                                                                                                                           \n\ntests/system/test_import.py .                                                                                                                         [ 50%]\ntests/unit/test_example.py .                                                                                                                          [100%]\n\n====================================================================== tests coverage =======================================================================\n_____________________________________________________ coverage: platform linux, python 3.11.12-final-0 ______________________________________________________\n\nName                           Stmts   Miss Branch BrPart    Cover   Missing\n----------------------------------------------------------------------------\nsrc/greatproject/__init__.py       0      0      0      0  100.00%\nsrc/greatproject/example.py        2      0      0      0  100.00%\n----------------------------------------------------------------------------\nTOTAL                              2      0      0      0  100.00%\n===================================================================== 2 passed in 0.05s =====================================================================\n\n\n\nYou can build your package using the environment and scripts defined in the build tables:\nhatch run build:check\nThis script builds and checks the output distribution files of your package.\nThis build environment table declares that pip and twine should be added to that environment. Adding pip to the environment ensures that it is a current, up-to-date version.\n[tool.hatch.envs.build]\ndescription = \"\"\"Build and test your package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\ndetached = true\n# This table installs created the command hatch run install:check which will build and check your package.\n[tool.hatch.envs.install.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\nThis uses the above environment and tells hatch to run\n\npip check, # verifies your dependencies\nhatch build --clean\n\ntwine check dist/* # this checks your distribution for metadata and other potential issues. to build and test your package."
  },
  {
    "objectID": "DEVELOPMENT.html#build-your-package",
    "href": "DEVELOPMENT.html#build-your-package",
    "title": "Development Guide",
    "section": "",
    "text": "You can build your package using the environment and scripts defined in the build tables:\nhatch run build:check\nThis script builds and checks the output distribution files of your package.\nThis build environment table declares that pip and twine should be added to that environment. Adding pip to the environment ensures that it is a current, up-to-date version.\n[tool.hatch.envs.build]\ndescription = \"\"\"Build and test your package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\ndetached = true\n# This table installs created the command hatch run install:check which will build and check your package.\n[tool.hatch.envs.install.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\nThis uses the above environment and tells hatch to run\n\npip check, # verifies your dependencies\nhatch build --clean\n\ntwine check dist/* # this checks your distribution for metadata and other potential issues. to build and test your package."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to data_fixr",
    "section": "",
    "text": "Package\n \n\n\nMeta\n\n\n\n\nTODO: the above badges that indicate python version and package version will only work if your package is on PyPI. If you don’t plan to publish to PyPI, you can remove them.\n\n\ndata_fixr is a lightweight Python package designed to support exploratory data analysis and early-stage data cleaning for tabular datasets. The package provides standardized, machine-readable diagnostics and cleaning utilities that help users quickly assess data quality, identify common issues, and prepare datasets for downstream analysis or machine learning workflows. Rather than generating plots or reports, data_fixr focuses on returning clean, structured outputs that can be easily tested, logged, or integrated into automated pipelines.\n\n\n\n\nCorrelation Report: Computes pairwise correlations between numeric columns in a pandas DataFrame and returns a long-format diagnostic table. The output summarizes the strength and direction of relationships between features in a standardized, machine-readable format suitable for exploratory analysis and preprocessing workflows.\nRemove Duplicates: Identifies and removes duplicate rows for a given dataset. Users can specify the retention strategy for handling duplicates and choose whether duplicates are detected using all columns or a specified subset. Optionally, the function can return a useful summary report describing the number of duplicate rows detected and removed.\nDetect Anomalies: This function identifies and flags outliers in numeric columns of a pandas DataFrame using either the Z-score method (for normally distributed data) or the IQR (Interquartile Range) method (for skewed data). It returns a DataFrame with the numeric columns and boolean outlier flags for each numeric column, as well as the overall percentage of outliers detected.\nMissing Values: This function fills missing values (NaN) in both numeric and categorical (non-numeric) columns of a pandas DataFrame. Numeric columns are filled using a user-specified method (mean, median, or mode), while categorical (non-numeric) columns are automatically filled using mode imputation. The function returns a DataFrame with missing values filled and the overall percentage of missing values that were imputed across all columns.\n\n\n\n\nThe functionality provided by data_fixr overlaps partially with capabilities available in established Python data analysis libraries, most notably pandas and scikit-learn. Pandas provides low-level methods for computing correlations between numeric variables and for removing duplicate rows, while scikit-learn and related libraries offer utilities for identifying outliers as part of preprocessing or feature selection workflows. However, these tools typically expose such functionality as individual operations without producing standardized, diagnostics-oriented summaries.\nIn particular, while duplicate removal and missing-value imputation functionality already exist in pandas, the corresponding functions in data_fixr extend this behavior by optionally returning structured summary information. The duplicate removal function can return a summary report describing how many duplicate rows were detected and removed, while the missing-value filling function reports the overall percentage of missing values that were imputed across the dataset. Additionally, automated exploratory data analysis tools such as ydata-profiling focus on generating comprehensive visual or HTML reports, whereas data_fixr emphasizes lightweight, modular functions that return machine-readable outputs intended for exploratory diagnostics, reproducible preprocessing pipelines, and downstream machine learning workflows.\n\n\n\nFirst, clone the repository:\n$ git clone https://github.com/UBC-MDS/data_fixr.git\nNavigate into the package directory:\n$ cd data_fixr\n(Optional) To run the package in a clean environment with Python 3.11.\n$ conda env create -f environment.yml\n$ conda activate data_fixr\nInstall the package in editable mode:\n$ pip install -e .\nTo run the tests (developer mode):\n$ pip install -e \".[tests]\"\n$ pytest \nIf you have opted to use the coda environment, deactivate the environment once finished with:\n$ conda deactivate\n\n\n\n\nPython ≥ 3.10\n\n\n\n\n\nApoorva Srivastava\nChikire Aku-Ibe\nNour Shawky\nZain Nofal\n\n\n\n\n\nCopyright © 2026 Nour Shawky, Apoorva Srivastava, Zain Nofal, Chikire Aku-Ibe .\nFree software distributed under the MIT License."
  },
  {
    "objectID": "index.html#package-summary",
    "href": "index.html#package-summary",
    "title": "Welcome to data_fixr",
    "section": "",
    "text": "data_fixr is a lightweight Python package designed to support exploratory data analysis and early-stage data cleaning for tabular datasets. The package provides standardized, machine-readable diagnostics and cleaning utilities that help users quickly assess data quality, identify common issues, and prepare datasets for downstream analysis or machine learning workflows. Rather than generating plots or reports, data_fixr focuses on returning clean, structured outputs that can be easily tested, logged, or integrated into automated pipelines."
  },
  {
    "objectID": "index.html#functions",
    "href": "index.html#functions",
    "title": "Welcome to data_fixr",
    "section": "",
    "text": "Correlation Report: Computes pairwise correlations between numeric columns in a pandas DataFrame and returns a long-format diagnostic table. The output summarizes the strength and direction of relationships between features in a standardized, machine-readable format suitable for exploratory analysis and preprocessing workflows.\nRemove Duplicates: Identifies and removes duplicate rows for a given dataset. Users can specify the retention strategy for handling duplicates and choose whether duplicates are detected using all columns or a specified subset. Optionally, the function can return a useful summary report describing the number of duplicate rows detected and removed.\nDetect Anomalies: This function identifies and flags outliers in numeric columns of a pandas DataFrame using either the Z-score method (for normally distributed data) or the IQR (Interquartile Range) method (for skewed data). It returns a DataFrame with the numeric columns and boolean outlier flags for each numeric column, as well as the overall percentage of outliers detected.\nMissing Values: This function fills missing values (NaN) in both numeric and categorical (non-numeric) columns of a pandas DataFrame. Numeric columns are filled using a user-specified method (mean, median, or mode), while categorical (non-numeric) columns are automatically filled using mode imputation. The function returns a DataFrame with missing values filled and the overall percentage of missing values that were imputed across all columns."
  },
  {
    "objectID": "index.html#position-in-python-environment",
    "href": "index.html#position-in-python-environment",
    "title": "Welcome to data_fixr",
    "section": "",
    "text": "The functionality provided by data_fixr overlaps partially with capabilities available in established Python data analysis libraries, most notably pandas and scikit-learn. Pandas provides low-level methods for computing correlations between numeric variables and for removing duplicate rows, while scikit-learn and related libraries offer utilities for identifying outliers as part of preprocessing or feature selection workflows. However, these tools typically expose such functionality as individual operations without producing standardized, diagnostics-oriented summaries.\nIn particular, while duplicate removal and missing-value imputation functionality already exist in pandas, the corresponding functions in data_fixr extend this behavior by optionally returning structured summary information. The duplicate removal function can return a summary report describing how many duplicate rows were detected and removed, while the missing-value filling function reports the overall percentage of missing values that were imputed across the dataset. Additionally, automated exploratory data analysis tools such as ydata-profiling focus on generating comprehensive visual or HTML reports, whereas data_fixr emphasizes lightweight, modular functions that return machine-readable outputs intended for exploratory diagnostics, reproducible preprocessing pipelines, and downstream machine learning workflows."
  },
  {
    "objectID": "index.html#get-started",
    "href": "index.html#get-started",
    "title": "Welcome to data_fixr",
    "section": "",
    "text": "First, clone the repository:\n$ git clone https://github.com/UBC-MDS/data_fixr.git\nNavigate into the package directory:\n$ cd data_fixr\n(Optional) To run the package in a clean environment with Python 3.11.\n$ conda env create -f environment.yml\n$ conda activate data_fixr\nInstall the package in editable mode:\n$ pip install -e .\nTo run the tests (developer mode):\n$ pip install -e \".[tests]\"\n$ pytest \nIf you have opted to use the coda environment, deactivate the environment once finished with:\n$ conda deactivate"
  },
  {
    "objectID": "index.html#requirements",
    "href": "index.html#requirements",
    "title": "Welcome to data_fixr",
    "section": "",
    "text": "Python ≥ 3.10"
  },
  {
    "objectID": "index.html#contributors",
    "href": "index.html#contributors",
    "title": "Welcome to data_fixr",
    "section": "",
    "text": "Apoorva Srivastava\nChikire Aku-Ibe\nNour Shawky\nZain Nofal"
  },
  {
    "objectID": "index.html#copyright",
    "href": "index.html#copyright",
    "title": "Welcome to data_fixr",
    "section": "",
    "text": "Copyright © 2026 Nour Shawky, Apoorva Srivastava, Zain Nofal, Chikire Aku-Ibe .\nFree software distributed under the MIT License."
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "All notable changes to this project will be documented in this file.\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning.\n\n\n\nUpcoming features and fixes\n\n\n\n\n\n\n\nFunction specifications and documentation for correlation_report() (#15)\nFunction specifications and documentation for detect_anomalies() (#16)\nFunction specifications and documentation for remove_duplicates() (#21)\nFunction specifications and documentation for missing_values() (#22)\nSupport for handling missing values in categorical columns (#17)\n\n\n\n\n\nUpdated README.md with project details and usage information (#24)\nUpdated CONTRIBUTING.md with contribution guidelines (#18)\nUpdated CODE_OF_CONDUCT.md with code of conduct (#23)\n\n\n\n\n\n\n\n\nImplementation of correlation_report() for computing pairwise correlations (#44)\nImplementation of detect_anomalies() for identifying outliers in data (#42)\nImplementation of remove_duplicates() for duplicate row detection and removal (#45)\nImplementation of missing_values() for handling missing data (#49)\nUnit tests for correlation_report() (#44)\nUnit tests for detect_anomalies() (#42)\nUnit tests for remove_duplicates() (#45)\nUnit tests for missing_values() (#49)\nDependencies added to pyproject.toml (#42)\nEnvironment configuration file environment.yml (#52)\n\n\n\n\n\nUpdated README.md installation instructions for clarity (#51, #52, #53)\n\n\n\n\n\nUpdated CHANGELOG.md to reflect Milestone 1 and 2 progress (#39)\nUpdated __init__.py with correct package imports (#53)"
  },
  {
    "objectID": "CHANGELOG.html#unreleased",
    "href": "CHANGELOG.html#unreleased",
    "title": "Changelog",
    "section": "",
    "text": "Upcoming features and fixes"
  },
  {
    "objectID": "CHANGELOG.html#milestone-1---2026-01-10",
    "href": "CHANGELOG.html#milestone-1---2026-01-10",
    "title": "Changelog",
    "section": "",
    "text": "Function specifications and documentation for correlation_report() (#15)\nFunction specifications and documentation for detect_anomalies() (#16)\nFunction specifications and documentation for remove_duplicates() (#21)\nFunction specifications and documentation for missing_values() (#22)\nSupport for handling missing values in categorical columns (#17)\n\n\n\n\n\nUpdated README.md with project details and usage information (#24)\nUpdated CONTRIBUTING.md with contribution guidelines (#18)\nUpdated CODE_OF_CONDUCT.md with code of conduct (#23)"
  },
  {
    "objectID": "CHANGELOG.html#milestone-2---2026-01-17",
    "href": "CHANGELOG.html#milestone-2---2026-01-17",
    "title": "Changelog",
    "section": "",
    "text": "Implementation of correlation_report() for computing pairwise correlations (#44)\nImplementation of detect_anomalies() for identifying outliers in data (#42)\nImplementation of remove_duplicates() for duplicate row detection and removal (#45)\nImplementation of missing_values() for handling missing data (#49)\nUnit tests for correlation_report() (#44)\nUnit tests for detect_anomalies() (#42)\nUnit tests for remove_duplicates() (#45)\nUnit tests for missing_values() (#49)\nDependencies added to pyproject.toml (#42)\nEnvironment configuration file environment.yml (#52)\n\n\n\n\n\nUpdated README.md installation instructions for clarity (#51, #52, #53)\n\n\n\n\n\nUpdated CHANGELOG.md to reflect Milestone 1 and 2 progress (#39)\nUpdated __init__.py with correct package imports (#53)"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Contributor Code of Conduct",
    "section": "",
    "text": "This Code of Conduct aims to create a welcoming, inclusive and harassment-free environment for all contributors. All participants are expected to treat each other with respect, and abusive or inappropriate behavior will not be tolerated.\n\n\nAs contributors and maintainers of this project, and in the interest of fostering an open and welcoming community, we pledge to respect all people who contribute through reporting issues, posting feature requests, submitting pull requests and other activities.\nWe are committed to making participation in this project a harassment-free experience for everybody, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion or nationality.\n\n\n\nTo foster an open and welcoming community, all contributors are expected to:\n\nUse welcoming and inclusive language in all interactions\nBe considerate of differing viewpoints and experiences\nAccept constructive criticism\nFocus on what is best for the community\nWork constructively with other contributors and be open to feedback\n\n\n\n\nExamples of unacceptable behavior by contributors include:\n\nThe use of sexualized language or imagery\nPersonal attacks, trolling or insulting/derogatory comments\nPublic or private harassment\nPublishing others’ private information, such as physical or electronic addresses, without explicit permission\nOther conduct which could reasonably be considered inappropriate, unethical or unprofessional\n\n\n\nProject maintainers have the right and responsibility to review and, if necessary, remove, edit or reject comments, code, issues and other contributions that are not aligned with this Code of Conduct.\nConsequences of violations may include:\n\nA written warning regarding their behavior\nTemporary restriction from interacting with the project for a specified period\nPermanent removal from the project and all associated spaces\n\nThe severity of the consequences will depend on the nature and frequency of the violation.\n\n\n\nInstances of abusive, harassing or otherwise unacceptable behavior may be reported by contacting any member of the project team directly or by e-mail: asrivas1@student.ubc.ca.\nWhen reporting an incident, please include your name and contact information, a description of the incident and any additional context that might be helpful. All complaints will be reviewed and investigated promptly and will result in a response that is deemed appropriate to the circumstances. All reports will be kept strictly confidential.\n\n\n\n\nThis Code of Conduct is adapted from the Pandas Code of Conduct, which was adapted from the Contributor Covenant, version 1.3.0, available at https://www.contributor-covenant.org/version/1/3/0/code-of-conduct/ and the Swift Code of Conduct."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#statement-on-diversity-and-inclusion",
    "href": "CODE_OF_CONDUCT.html#statement-on-diversity-and-inclusion",
    "title": "Contributor Code of Conduct",
    "section": "",
    "text": "As contributors and maintainers of this project, and in the interest of fostering an open and welcoming community, we pledge to respect all people who contribute through reporting issues, posting feature requests, submitting pull requests and other activities.\nWe are committed to making participation in this project a harassment-free experience for everybody, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion or nationality."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#expected-behavior",
    "href": "CODE_OF_CONDUCT.html#expected-behavior",
    "title": "Contributor Code of Conduct",
    "section": "",
    "text": "To foster an open and welcoming community, all contributors are expected to:\n\nUse welcoming and inclusive language in all interactions\nBe considerate of differing viewpoints and experiences\nAccept constructive criticism\nFocus on what is best for the community\nWork constructively with other contributors and be open to feedback"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#unacceptable-behavior",
    "href": "CODE_OF_CONDUCT.html#unacceptable-behavior",
    "title": "Contributor Code of Conduct",
    "section": "",
    "text": "Examples of unacceptable behavior by contributors include:\n\nThe use of sexualized language or imagery\nPersonal attacks, trolling or insulting/derogatory comments\nPublic or private harassment\nPublishing others’ private information, such as physical or electronic addresses, without explicit permission\nOther conduct which could reasonably be considered inappropriate, unethical or unprofessional\n\n\n\nProject maintainers have the right and responsibility to review and, if necessary, remove, edit or reject comments, code, issues and other contributions that are not aligned with this Code of Conduct.\nConsequences of violations may include:\n\nA written warning regarding their behavior\nTemporary restriction from interacting with the project for a specified period\nPermanent removal from the project and all associated spaces\n\nThe severity of the consequences will depend on the nature and frequency of the violation.\n\n\n\nInstances of abusive, harassing or otherwise unacceptable behavior may be reported by contacting any member of the project team directly or by e-mail: asrivas1@student.ubc.ca.\nWhen reporting an incident, please include your name and contact information, a description of the incident and any additional context that might be helpful. All complaints will be reviewed and investigated promptly and will result in a response that is deemed appropriate to the circumstances. All reports will be kept strictly confidential."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Contributor Code of Conduct",
    "section": "",
    "text": "This Code of Conduct is adapted from the Pandas Code of Conduct, which was adapted from the Contributor Covenant, version 1.3.0, available at https://www.contributor-covenant.org/version/1/3/0/code-of-conduct/ and the Swift Code of Conduct."
  },
  {
    "objectID": "docs/index.html",
    "href": "docs/index.html",
    "title": "Welcome to data_fixr’s Documentation ’",
    "section": "",
    "text": ":maxdepth: 2 :hidden: :caption: Contents:\nHome \n\nThis is the landing page of your docs. you can update it as you’d like to. This documentation example uses myst markdown as the primary documentation syntax.\n:::{button-link} https://www.pyopensci.org/python-package-guide/documentation/hosting-tools/myst-markdown-rst-doc-syntax.html :color: primary :class: sd-rounded-pill float-left\nLearn more about myst in our pyOpenSci packaging guide.\n:::\nMyst is a version of markdown that has more formatting flexibility. This is what a sphinx directive looks like using myst markdown formatting:\n:::{toctree}\n:maxdepth: 2\n:caption: Contents:\n:::\nIf you see syntax like the syntax below, you are looking at rst.\n.. toctree::\n   :maxdepth: 2\n   :caption: Contents:\n\n\n\n\nCopyright © 2026 Nour Shawky, Apoorva Srivastava, Zain Nofal, Chikire Aku-Ibe .\nFree software distributed under the MIT License."
  },
  {
    "objectID": "docs/index.html#overview",
    "href": "docs/index.html#overview",
    "title": "Welcome to data_fixr’s Documentation ’",
    "section": "",
    "text": ":maxdepth: 2 :hidden: :caption: Contents:\nHome \n\nThis is the landing page of your docs. you can update it as you’d like to. This documentation example uses myst markdown as the primary documentation syntax.\n:::{button-link} https://www.pyopensci.org/python-package-guide/documentation/hosting-tools/myst-markdown-rst-doc-syntax.html :color: primary :class: sd-rounded-pill float-left\nLearn more about myst in our pyOpenSci packaging guide.\n:::\nMyst is a version of markdown that has more formatting flexibility. This is what a sphinx directive looks like using myst markdown formatting:\n:::{toctree}\n:maxdepth: 2\n:caption: Contents:\n:::\nIf you see syntax like the syntax below, you are looking at rst.\n.. toctree::\n   :maxdepth: 2\n   :caption: Contents:"
  },
  {
    "objectID": "docs/index.html#copyright",
    "href": "docs/index.html#copyright",
    "title": "Welcome to data_fixr’s Documentation ’",
    "section": "",
    "text": "Copyright © 2026 Nour Shawky, Apoorva Srivastava, Zain Nofal, Chikire Aku-Ibe .\nFree software distributed under the MIT License."
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing",
    "section": "",
    "text": "Contributions of all kinds are welcome for the data_fixr package and are greatly appreciated! Every little bit helps, and credit will always be given.\n\n\nThis project follows a Github Flow Workflow.\n\nThe main branch always contains stable, production-ready code\nDirect commits to the ‘main’ branch are prohibited.\nAll work should be conducted on short-lived branches created from ‘main’.\nBranches should be named using appropriate prefixes such as ‘feat-’ or ‘fix-’.\nChanges must be proposed via pull request to the main branch.\nEach Pull request must be reviewed by at least one other team member and granted approval before merging.\n\n\n\n\nYou can contribute in many ways, for example:\n\nReport bugs\nFix Bugs\nImplement Features\nWrite Documentation\nSubmit Feedback\n\n\n\nReport bugs at https://github.com/UBC-MDS/data_fixr/issues.\nIf you are reporting a bug, please follow the template guidelines. The more detailed your report, the easier and thus faster we can help you.\n\n\n\nLook through the GitHub issues for bugs. Anything labelled with bug and help wanted is open to whoever wants to implement it. When you decide to work on such an issue, please assign yourself to it and add a comment that you’ll be working on that, too. If you see another issue without the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nLook through the GitHub issues for features. Anything labelled with enhancement and help wanted is open to whoever wants to implement it. As for fixing bugs, please assign yourself to the issue and add a comment that you’ll be working on that, too. If another enhancement catches your fancy, but it doesn’t have the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\ndata_fixr could always use more documentation, whether as part of the official documentation, in docstrings, or even on the web in blog posts, articles, and such. Just open an issue to let us know what you will be working on so that we can provide you with guidance.\n\n\n\nThe best way to send feedback is to file an issue at https://github.com/UBC-MDS/data_fixr/issues. If your feedback fits the format of one of the issue templates, please use that. Remember that this is a volunteer-driven project and everybody has limited time.\n\n\n\n\nReady to contribute? Here’s how to set up data_fixr for local development.\n\nFork the https://github.com/UBC-MDS/data_fixr repository on GitHub.\nClone your fork locally (if you want to work locally)\ngit clone git@github.com:your_name_here/data_fixr.git\nInstall hatch.\nCreate a branch for local development using the default branch (typically main) as a starting point. Use fix or feat as a prefix for your branch name.\ngit checkout main\ngit checkout -b fix-name-of-your-bugfix\nNow you can make your changes locally.\nWhen you’re done making changes, apply the quality assurance tools and check that your changes pass our test suite. This is all included with Hatch.\nhatch run test:run\nCommit your changes and push your branch to GitHub. Please use semantic commit messages.\ngit add .\ngit commit -m \"fix: summarize your changes\"\ngit push -u origin fix-name-of-your-bugfix\nOpen the link displayed in the message when pushing your new branch in order to submit a pull request.\n\n\n\n\nBefore you submit a pull request, check that it meets these guidelines:\n\nThe pull request should include tests.\nIf the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring.\nYour pull request will automatically be checked by the full test suite. It needs to pass all of them before it can be considered for merging.\n\n\n\n\nPlease note that the data_fixr package is released with a Code of Conduct. By contributing to this project you agree to abide by its terms."
  },
  {
    "objectID": "CONTRIBUTING.html#branching-and-workflow",
    "href": "CONTRIBUTING.html#branching-and-workflow",
    "title": "Contributing",
    "section": "",
    "text": "This project follows a Github Flow Workflow.\n\nThe main branch always contains stable, production-ready code\nDirect commits to the ‘main’ branch are prohibited.\nAll work should be conducted on short-lived branches created from ‘main’.\nBranches should be named using appropriate prefixes such as ‘feat-’ or ‘fix-’.\nChanges must be proposed via pull request to the main branch.\nEach Pull request must be reviewed by at least one other team member and granted approval before merging."
  },
  {
    "objectID": "CONTRIBUTING.html#example-contributions",
    "href": "CONTRIBUTING.html#example-contributions",
    "title": "Contributing",
    "section": "",
    "text": "You can contribute in many ways, for example:\n\nReport bugs\nFix Bugs\nImplement Features\nWrite Documentation\nSubmit Feedback\n\n\n\nReport bugs at https://github.com/UBC-MDS/data_fixr/issues.\nIf you are reporting a bug, please follow the template guidelines. The more detailed your report, the easier and thus faster we can help you.\n\n\n\nLook through the GitHub issues for bugs. Anything labelled with bug and help wanted is open to whoever wants to implement it. When you decide to work on such an issue, please assign yourself to it and add a comment that you’ll be working on that, too. If you see another issue without the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nLook through the GitHub issues for features. Anything labelled with enhancement and help wanted is open to whoever wants to implement it. As for fixing bugs, please assign yourself to the issue and add a comment that you’ll be working on that, too. If another enhancement catches your fancy, but it doesn’t have the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\ndata_fixr could always use more documentation, whether as part of the official documentation, in docstrings, or even on the web in blog posts, articles, and such. Just open an issue to let us know what you will be working on so that we can provide you with guidance.\n\n\n\nThe best way to send feedback is to file an issue at https://github.com/UBC-MDS/data_fixr/issues. If your feedback fits the format of one of the issue templates, please use that. Remember that this is a volunteer-driven project and everybody has limited time."
  },
  {
    "objectID": "CONTRIBUTING.html#get-started",
    "href": "CONTRIBUTING.html#get-started",
    "title": "Contributing",
    "section": "",
    "text": "Ready to contribute? Here’s how to set up data_fixr for local development.\n\nFork the https://github.com/UBC-MDS/data_fixr repository on GitHub.\nClone your fork locally (if you want to work locally)\ngit clone git@github.com:your_name_here/data_fixr.git\nInstall hatch.\nCreate a branch for local development using the default branch (typically main) as a starting point. Use fix or feat as a prefix for your branch name.\ngit checkout main\ngit checkout -b fix-name-of-your-bugfix\nNow you can make your changes locally.\nWhen you’re done making changes, apply the quality assurance tools and check that your changes pass our test suite. This is all included with Hatch.\nhatch run test:run\nCommit your changes and push your branch to GitHub. Please use semantic commit messages.\ngit add .\ngit commit -m \"fix: summarize your changes\"\ngit push -u origin fix-name-of-your-bugfix\nOpen the link displayed in the message when pushing your new branch in order to submit a pull request."
  },
  {
    "objectID": "CONTRIBUTING.html#pull-request-guidelines",
    "href": "CONTRIBUTING.html#pull-request-guidelines",
    "title": "Contributing",
    "section": "",
    "text": "Before you submit a pull request, check that it meets these guidelines:\n\nThe pull request should include tests.\nIf the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring.\nYour pull request will automatically be checked by the full test suite. It needs to pass all of them before it can be considered for merging."
  },
  {
    "objectID": "CONTRIBUTING.html#code-of-conduct",
    "href": "CONTRIBUTING.html#code-of-conduct",
    "title": "Contributing",
    "section": "",
    "text": "Please note that the data_fixr package is released with a Code of Conduct. By contributing to this project you agree to abide by its terms."
  }
]